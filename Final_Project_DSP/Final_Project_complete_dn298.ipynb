{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dn298/dsp/lib/python3.6/site-packages/librosa/util/decorators.py:9: NumbaDeprecationWarning: An import was requested from a module that has moved location.\n",
      "Import of 'jit' requested from: 'numba.decorators', please update to use 'numba.core.decorators' or pin to Numba version 0.48.0. This alias will not be present in Numba version 0.50.0.\n",
      "  from numba.decorators import jit as optional_jit\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numba as nb\n",
    "import librosa as lib\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import librosa.display\n",
    "import IPython.display\n",
    "from scipy.fftpack import dct\n",
    "from scipy.fftpack import idct\n",
    "from math import pi\n",
    "from math import e\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_voice = pd.read_csv('common-voice/cv-valid-train.csv')\n",
    "train_noise = pd.read_csv('UrbanSound8K/metadata/UrbanSound8K.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "voice = list(train_voice.filename.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_nums = [1,2,3,4,5,6,7,8,9,10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def organize_data(voice, noise_data, fold_nums):\n",
    "    result = {}\n",
    "    result['voice'] = []\n",
    "    result['combined'] = []\n",
    "    count = 0\n",
    "    for fold_num in fold_nums:\n",
    "        noise = list(noise_data[noise_data.fold == fold_num][noise_data['class'] == 'children_playing'].slice_file_name)\n",
    "        for i in range(len(noise)):\n",
    "            sample_voice = list(lib.load('common-voice/cv-valid-train/' + voice[count])[0])\n",
    "            sample_noise = list(lib.load('UrbanSound8K/audio/fold{}/'.format(fold_num) + noise[i])[0])\n",
    "            extended_noise = sample_noise\n",
    "\n",
    "            while len(sample_voice) > len(extended_noise):\n",
    "                extended_noise.extend(sample_noise)\n",
    "\n",
    "            sample_combined = []\n",
    "            for val1, val2 in zip(sample_voice, extended_noise):\n",
    "                sample_combined.append(val1 + val2)\n",
    "\n",
    "            result['voice'].append(sample_voice)\n",
    "            result['combined'].append(sample_combined)\n",
    "            count += 1\n",
    "        print('Success')\n",
    "        \n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MLT_window(N):\n",
    "    helper = []\n",
    "    \n",
    "    for n in range(N):\n",
    "        helper.append(np.sin(pi*((n+.5)/N)))\n",
    "        \n",
    "    return helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_stdct(sample, W, m, L, N):\n",
    "    s_hat = []\n",
    "    \n",
    "    for i in range(len(m)):\n",
    "        W_sample = np.multiply(W, sample[m[i]:m[i] + N])\n",
    "        DCT = dct(W_sample, norm = 'ortho')\n",
    "        s_hat.append(DCT)\n",
    "    \n",
    "    return s_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward_stdct(s_hat, W, m, L, N):\n",
    "    s_new = [0.0]*L\n",
    "    \n",
    "    for i in range(len(m)):\n",
    "        IDCT = idct(s_hat[i].to('cpu').detach().numpy(), norm = 'ortho')\n",
    "        helper = np.multiply(W, IDCT)\n",
    "        s_new[m[i]:m[i]+N] += helper\n",
    "        \n",
    "    return s_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_data(data, labels, W, N, data_str, label_str, cuda):\n",
    "    data_dict = {}\n",
    "    data_dict[data_str] = defaultdict(list)\n",
    "    data_dict[label_str] = defaultdict(list)\n",
    "    for n in range(len(data)):\n",
    "        L = len(data[n])\n",
    "        m = [int(i*(N/2)) for i in range(int((2*L/N) - 1))]\n",
    "        s_hat = forward_stdct(data[n], W, m, L, N)\n",
    "        label_hat = forward_stdct(labels[n], W, m, L, N)\n",
    "        length = len(s_hat)\n",
    "        for i in range(length):\n",
    "            if (i > 1):\n",
    "                prev2_window = s_hat[i - 2]\n",
    "                prev1_window = s_hat[i-1]\n",
    "                cur_window = s_hat[i]\n",
    "                new_cur_vector = np.array([prev2_window, prev1_window, cur_window]).flatten()\n",
    "                current_torch_vector = torch.tensor(new_cur_vector, dtype = torch.double, device = cuda)\n",
    "                data_dict[data_str]['noisy_sample_{}'.format(n)].append(current_torch_vector)\n",
    "                \n",
    "                current_torch_vector_label = torch.tensor(label_hat[i], dtype = torch.double, device = cuda)\n",
    "                data_dict[label_str]['voice_sample_{}'.format(n)].append(current_torch_vector_label)\n",
    "                \n",
    "            elif i == 0:\n",
    "                zeros = [0]*N\n",
    "                \n",
    "                first_window = s_hat[0]\n",
    "                first_vector = np.array([zeros, zeros, first_window]).flatten()\n",
    "                torch_vector = torch.tensor(first_vector, dtype = torch.double, device = cuda)\n",
    "                data_dict[data_str]['noisy_sample_{}'.format(n)].append(torch_vector)\n",
    "                \n",
    "                torch_vector_label = torch.tensor(label_hat[0], dtype = torch.double, device = cuda)\n",
    "                data_dict[label_str]['voice_sample_{}'.format(n)].append(torch_vector_label)\n",
    "            \n",
    "            elif i == 1:\n",
    "                zeros = [0]*N\n",
    "                \n",
    "                first_window = s_hat[0]\n",
    "                second_window = s_hat[1]\n",
    "                second_vector = np.array([zeros, first_window, second_window]).flatten()\n",
    "                second_torch_vector = torch.tensor(second_vector, dtype = torch.double, device = cuda)\n",
    "                data_dict[data_str]['noisy_sample_{}'.format(n)].append(second_torch_vector)\n",
    "                \n",
    "                second_torch_vector_label = torch.tensor(label_hat[1], dtype = torch.double, device = cuda)\n",
    "                data_dict[label_str]['voice_sample_{}'.format(n)].append(second_torch_vector_label)\n",
    "        \n",
    "    return data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FourLayerNet(nn.Module):\n",
    "    \n",
    "    def __init__(self, Din, H1, H2, H3, Dout):\n",
    "        super(FourLayerNet, self).__init__()\n",
    "        \n",
    "        self.linear1 = nn.Linear(Din, H1)\n",
    "        self.linear2 = nn.Linear(H1, H2)\n",
    "        self.linear3 = nn.Linear(H2, H3)\n",
    "        self.linear4 = nn.Linear(H3, Dout)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        first = F.elu(self.linear1(x))\n",
    "        second = F.selu(self.linear2(first))\n",
    "        third = F.gelu(self.linear3(second))\n",
    "        fourth = self.linear4(third)\n",
    "        \n",
    "        return fourth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ThreeLayerNet(nn.Module):\n",
    "    \n",
    "    def __init__(self, Din, H1, H2, Dout):\n",
    "        super(ThreeLayerNet, self).__init__()\n",
    "        \n",
    "        self.linear1 = nn.Linear(Din, H1)\n",
    "        self.linear2 = nn.Linear(H1, H2)\n",
    "        self.linear3 = nn.Linear(H2, Dout)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        first = F.selu(self.linear1(x))\n",
    "        second = F.gelu(self.linear2(first))\n",
    "        third = self.linear3(second)\n",
    "        \n",
    "        return third"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TwoLayerNet(nn.Module):\n",
    "    \n",
    "    def __init__(self, Din, H1, Dout):\n",
    "        super(TwoLayerNet, self).__init__()\n",
    "        \n",
    "        self.linear1 = nn.Linear(Din, H1)\n",
    "        self.linear2 = nn.Linear(H1, Dout)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        first = F.tanh(self.linear1(x))\n",
    "        second = self.linear2(first)\n",
    "        \n",
    "        return second"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_network(model, num_epochs, loss_fn, optimizer, train_data):\n",
    "    for t in range(num_epochs):\n",
    "        total_loss = []\n",
    "        for index in range(len(train_data['train_data'])):\n",
    "            x = torch.stack(train_data['train_data']['noisy_sample_{}'.format(index)]).to(cuda)\n",
    "            y = torch.stack(train_data['train_labels']['voice_sample_{}'.format(index)]).to(cuda)\n",
    "            y_pred = model.forward(x)\n",
    "\n",
    "            loss = loss_fn(y_pred, y)\n",
    "            total_loss.append(loss.item())\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        if t%10 == 0:\n",
    "            print(t, np.mean(total_loss))\n",
    "            \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(validation_data, validation_data_dict, model):\n",
    "    mse_original = []\n",
    "    mse_dirty = []\n",
    "    mse_clean = []\n",
    "    for i in range(len(validation_data_dict['validation_data'])):\n",
    "        L = len(validation_data['combined'][i])\n",
    "        N = 128\n",
    "        W = MLT_window(N)\n",
    "        m = [int(i*(N/2)) for i in range(int((2*L/N)-1))]\n",
    "        \n",
    "        changed_shat_val = []\n",
    "        for el in validation_data_dict['validation_data']['noisy_sample_{}'.format(i)]:\n",
    "            changed_shat_val.append(model(el))\n",
    "        \n",
    "        s_new_val = backward_stdct(changed_shat_val, W, m, L, N)\n",
    "        s_new_clean = backward_stdct(validation_data_dict['validation_labels']['voice_sample_{}'.format(i)], W, m, L, N)\n",
    "        s_new_dirty = validation_data['combined'][i]\n",
    "        \n",
    "        mse_original.append(mse(s_new_dirty[N:len(s_new_val)-N], s_new_clean[N:len(s_new_val)-N]))\n",
    "        mse_dirty.append(mse(s_new_val[N:len(s_new_val)-N], s_new_dirty[N:len(s_new_val)-N]))\n",
    "        mse_clean.append(mse(s_new_val[N:len(s_new_val)-N], s_new_clean[N:len(s_new_val)-N]))\n",
    "        \n",
    "    print('Average MSE between the original noisy and clean signal: {}'.format(np.mean(mse_original)))\n",
    "    print('Average MSE between model output and noisy singal: {}'.format(np.mean(mse_dirty)))\n",
    "    print('Average MSE between model output and clean signal: {}'.format(np.mean(mse_clean)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success\n",
      "Success\n",
      "Success\n",
      "Success\n",
      "Success\n",
      "Success\n"
     ]
    }
   ],
   "source": [
    "train_data = organize_data(voice, train_noise, fold_nums[:6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_dict = transform_data(train_data['combined'], train_data['voice'], W, N, 'train_data', 'train_labels', cuda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network Model Instantiation and Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = FourLayerNet(128*3, int(128*2.5), 128*2, int(128*1.5), 128).double().to(cuda)\n",
    "optimizer1 = torch.optim.Adam(model1.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = ThreeLayerNet(128*3, int(128*2.5), int(128*1.5), 128).double().to(cuda)\n",
    "optimizer2 = torch.optim.Adam(model2.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = TwoLayerNet(128*3, 128*2, 128).double().to(cuda)\n",
    "optimizer3 = torch.optim.Adam(model3.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = nn.MSELoss(reduction = 'mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.001188422360564077\n",
      "10 0.0007634426073312159\n",
      "20 0.0007556456462319581\n",
      "30 0.0007498989407183789\n",
      "40 0.0007448335659721771\n",
      "50 0.0007420943784799458\n",
      "60 0.0007398044751288581\n",
      "70 0.0007379940314625577\n",
      "80 0.000736326497608683\n",
      "90 0.000734881670237516\n",
      "100 0.0007340140764064712\n",
      "110 0.0007324249396463482\n",
      "120 0.0007314613267109296\n",
      "130 0.0007311715470258406\n",
      "140 0.0007303210944592649\n",
      "150 0.0007294768820255279\n",
      "160 0.0007288913247468209\n",
      "170 0.0007283497067206976\n",
      "180 0.0007277409462604447\n",
      "190 0.000726860762847975\n"
     ]
    }
   ],
   "source": [
    "two_layer_net = train_network(model3, 200, loss_function, optimizer3, train_data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.001221295324761317\n",
      "10 0.000736445912133225\n",
      "20 0.0006751473652961667\n",
      "30 0.0006482751691584887\n",
      "40 0.0006329092781529569\n",
      "50 0.0006201950451189576\n",
      "60 0.0006085090982240824\n",
      "70 0.0006012241386874764\n",
      "80 0.0005942088706933905\n",
      "90 0.0005884122826419335\n",
      "100 0.0005822178414069758\n",
      "110 0.0005756504298278776\n",
      "120 0.0005698992752151779\n",
      "130 0.0005650527128793198\n",
      "140 0.0005590968373351507\n",
      "150 0.0005547059383862573\n",
      "160 0.0005515159772711032\n",
      "170 0.000549775316513866\n",
      "180 0.0005463910012885757\n",
      "190 0.0005439800172332671\n"
     ]
    }
   ],
   "source": [
    "three_layer_net = train_network(model2, 200, loss_function, optimizer2, train_data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.0013330905394985696\n",
      "10 0.0007585145118679859\n",
      "20 0.0006759971341091145\n",
      "30 0.0006373938851638815\n",
      "40 0.0006116250622458589\n",
      "50 0.0005943550895553765\n",
      "60 0.0005817334352666519\n",
      "70 0.0005696276244184572\n",
      "80 0.0005579512547373587\n",
      "90 0.0005505735765437926\n",
      "100 0.000546246113433163\n",
      "110 0.0005394817035597474\n",
      "120 0.0005354037170536995\n",
      "130 0.0005290663780511821\n",
      "140 0.00052627970405805\n",
      "150 0.0005185233534035745\n",
      "160 0.0005149426988342548\n",
      "170 0.000511807926000944\n",
      "180 0.0005061297978466665\n",
      "190 0.0005022031844768415\n"
     ]
    }
   ],
   "source": [
    "four_layer_net = train_network(model1, 200, loss_function, optimizer1, train_data_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success\n",
      "Success\n"
     ]
    }
   ],
   "source": [
    "validation_data = organize_data(voice, train_noise, fold_nums[6:8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_data_dict = transform_data(validation_data['combined'], validation_data['voice'], W, N, 'validation_data', 'validation_labels', cuda)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average MSE between the original noisy and clean signal: 0.004261348032147487\n",
      "Average MSE between model output and noisy singal: 0.002390543012499608\n",
      "Average MSE between model output and clean signal: 0.0020025144240509484\n"
     ]
    }
   ],
   "source": [
    "validation(validation_data, validation_data_dict, two_layer_net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average MSE between the original noisy and clean signal: 0.004261348032147487\n",
      "Average MSE between model output and noisy singal: 0.0021596526064831013\n",
      "Average MSE between model output and clean signal: 0.0017421923142928585\n"
     ]
    }
   ],
   "source": [
    "validation(validation_data, validation_data_dict, three_layer_net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average MSE between the original noisy and clean signal: 0.004261348032147487\n",
      "Average MSE between model output and noisy singal: 0.0023164105534484677\n",
      "Average MSE between model output and clean signal: 0.0016182336587833041\n"
     ]
    }
   ],
   "source": [
    "validation(validation_data, validation_data_dict, four_layer_net)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
